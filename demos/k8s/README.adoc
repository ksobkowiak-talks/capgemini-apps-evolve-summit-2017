# Demo Walkthrough

## Demo Preparation

During this demo we will use link:https://fabric8.io[Fabric8] running on top of link:https://github.com/minishift/minishift[Minishift].

### Install Fabric8

You can install Fabric8 in several methods. One of the simplest method is to use Gofabric8. You can simply install it using `fabric8-maven-plugin`

  $ mvn io.fabric8:fabric8-maven-plugin:3.2.28:install -Dfabric8.cluster.kind=openshift

This will download and install all necessary binaries under `~/.fabric8/bin`. Please follow the instructions on the screen.
There is a bug in Gofabric9 actually and the OpenShift client cannot be downloaded successfully. Please download it manually.

  $ wget https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-linux-64bit.tar.gz
  $ tar xvf openshift-origin-client-tools-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-linux-64bit.tar.gz -C ~/.fabric8/bin/ --strip-components=1

You can start now Fabric8 using following comand

  $ gofabric8 start --minishift --vm-driver virtualbox --cpus 2 --memory 6000 --batch

You can also start Gofabric8 using one single command

  $ mvn io.fabric8:fabric8-maven-plugin:3.2.28:cluster-start -Dfabric8.cluster.kind=openshift -Dfabric8.cluster.app=platform -Dfabric8.cluster.cpus=4 -Dfabric8.cluster.memory=9000 -Dfabric8.cluster.driver=virtualbox

### Install router

OpenShift `0.9.0` has no router installed. The services are not accessible via routes. We need to install the router.

You should download OpenShift administration tool and install the router using it

----
$ wget https://github.com/openshift/origin/releases/download/v1.3.1/openshift-origin-server-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-linux-64bit.tar.gz
$ tar xvf openshift-origin-server-v1.3.1-dad658de7465ba8a234a4fb40b5b446a45a4cee1-linux-64bit.tar.gz -C . --strip-components=1
$ ./oadm router
----

### Install image streams and templates

Read the link:https://docs.openshift.org/latest/install_config/imagestreams_templates.html[Loading the Default Image Streams and Templates] in the official documentation to learn how to load the templates.

### Install JBoss Forge

Install link:https://forge.jboss.org/[JBoss Forge] and link:http://fabric8.io/guide/forge.html[Fabric8 addons].

## Simple Hello Minishift Demo

This demo shows how to create an application using ready docker image and how to expose the container using route.

----
  $ oc run hello-minishift --image=gcr.io/google_containers/echoserver:1.4
  deploymentconfig "hello-minishift" created

  $ oc expose dc hello-minishift --type=NodePort --port=8080
  service "hello-minishift" exposed
----

or using one command

----
  $ oc run hello-minishift --image=gcr.io/google_containers/echoserver:1.4 --port=8080 --expose --service-overrides='{"apiVersion": "v1", "spec": {"type": "NodePort"}}'
  service "hello-minishift" created
  deploymentconfig "hello-minishift" created
----

----
  $ minishift service hello-minishift --url
  http://192.168.99.101:31459

  $ curl $(minishift service hello-minishift --url)
  CLIENT VALUES:
  client_address=172.17.0.1
  command=GET
  real path=/
  ....

  $ oc get service
  NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)                   AGE
  hello-minishift           172.30.145.254   <nodes>       8080/TCP                  7m

  $ oc expose svc hello-minishift
  route "hello-minishift" exposed

  $ oc get route
  NAME              HOST/PORT                                       PATH      SERVICES          PORT      TERMINATION
  hello-minishift   hello-minishift-default.192.168.99.101.xip.io             hello-minishift   8080

  $ curl http://hello-minishift-default.192.168.99.101.xip.io
  CLIENT VALUES:
  client_address=172.17.0.1
  command=GET
  real path=/
  ...
----

## Simple Source-to-Image Demo

This demo shows how to create an application using source repository and s2i image.

----
$ oc new-app openshift/ruby-20-centos7~https://github.com/openshift/ruby-ex
--> Found Docker image 54ccc57 (12 weeks old) from Docker Hub for "openshift/ruby-20-centos7"

    Ruby 2.0
    --------
    Platform for building and running Ruby 2.0 applications

    Tags: builder, ruby, ruby20

    * An image stream will be created as "ruby-20-centos7:latest" that will track the source image
    * A source build using source code from https://github.com/openshift/ruby-ex will be created
      * The resulting image will be pushed to image stream "ruby-ex:latest"
      * Every time "ruby-20-centos7:latest" changes a new build will be triggered
    * This image will be deployed in deployment config "ruby-ex"
    * Port 8080/tcp will be load balanced by service "ruby-ex"
      * Other containers can access this service through the hostname "ruby-ex"

--> Creating resources with label app=ruby-ex ...
    imagestream "ruby-20-centos7" created
    imagestream "ruby-ex" created
    buildconfig "ruby-ex" created
    deploymentconfig "ruby-ex" created
    service "ruby-ex" created
--> Success
    Build scheduled, use 'oc logs -f bc/ruby-ex' to track its progress.
    Run 'oc status' to view your app.

$ oc expose svc ruby-ex
route "ruby-ex" exposed

$ oc get route
NAME      HOST/PORT                               PATH      SERVICES   PORT       TERMINATION
ruby-ex   ruby-ex-default.192.168.99.101.xip.io             ruby-ex    8080-tcp

$ curl http://ruby-ex-default.192.168.99.101.xip.io
...
----

## Spring Boot microservices demo

### Implement simple `ipservice` application

. Create a new Spring Boot application using link:https://start.spring.io/[Spring Initializr] or JBoss Forge extension in your IDE
. Implement simple rest service
+
[source, java]
----
package com.capgemini.demos.k8s.ipservice;

....

@RestController
class IPAddressController {
    private int counter;

    @Autowired
    private Config config;

    @RequestMapping(value = "/ip", method = RequestMethod.GET)
    public IPAddress ipaddress() throws Exception {
        return new IPAddress(++counter, InetAddress.getLocalHost().getHostAddress(), config.getMessage());
    }
}

class IPAddress {
    private final long id;
    private final String ipAddress;
    private String message;

    public IPAddress(long id, String ipAddress, String message) {
        this.id = id;
        this.ipAddress = ipAddress;
        this.message = message;
    }

    ....
}

@Configuration
@ConfigurationProperties(prefix = "ipservice")
public class Config {
    private String message;

    public String getMessage() {
        return message;
    }

    public void setMessage(String message) {
        this.message = message;
    }

}
----
+
. Add some configuration properties to `application.properties`
+
----
spring.application.name=ipservice
ipservice.message=Hello from IDE
----
+
. Start the application and test it
+
----
$ curl -s http://localhost:8080/ip
----

### Configure your environment to use Docker from OpenShift

[source, bash]
----
$ minishift docker-env
export DOCKER_TLS_VERIFY="1"
export DOCKER_HOST="tcp://192.168.99.100:2376"
export DOCKER_CERT_PATH="/home/kso/.minishift/certs"
export DOCKER_API_VERSION="1.23"
# Run this command to configure your shell:
# eval $(minishift docker-env)

$ eval $(minishift docker-env)
----

### Deploy `ipservice` on OpenShift

. Add `fabric8-maven-plugin` to the project pom
+
[source,xml]
----
<plugin>
  <groupId>io.fabric8</groupId>
  <artifactId>fabric8-maven-plugin</artifactId>
  <version>3.2.28</version>
  <executions>
    <execution>
      <id>fmp</id>
      <goals>
        <goal>resource</goal>
      </goals>
    </execution>
  </executions>
</plugin>
----
+
You can add the plugin using the forge command `Fabric8: Setup` option or using maven command
+
----
$ mvn io.fabric8:fabric8-maven-plugin:3.2.28:setup
----
+
. Generate OpenShift and Kubernetes resources using
+
----
$ mvn fabric8:resource
----
+
Inspect the generated files under `target/classes/META-INF/fabric8`
+
This step is usually performed automatically
+
. Build the application
+
----
$ mvn clean install fabric8:build -Dfabric8.mode=openshift
----
+
This creates a `BuildConfig` in OpenShift and starts the buiild. You can observe the logs using
+
----
$ oc log bc/ipservice
----
+
. Deploy the `ipservice`
+
----
$ mvn fabric8:deploy
----
+
It will create `DeploymentConfig`, pods, service and routs. Watch the progress using
+
----
$ oc get pods -w
----
+
. Test the deployed application
+
----
$ oc get svc
NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)                   AGE
ipservice                 172.30.12.104    <nodes>       80/TCP                    3m

$ oc get route
NAME             HOST/PORT                                      PATH      SERVICES         PORT       TERMINATION
ipservice        ipservice-default.192.168.99.100.xip.io                  ipservice        8080

$ curl -s http://ipservice-default.192.168.99.100.xip.io/ip
{"id":1,"ipAddress":"172.17.0.19","message":"Hello from IDE"}
----
+
. Scale the deployment
+
----
$ oc scale dc ipservice --replicas=3
deploymentconfig "ipservice" scaled

$ for i in {1..10}; do curl -s http://ipservice-default.192.168.99.100.xip.io/ip |  python -m json.tool; done;
{
    "id": 1,
    "ipAddress": "172.17.0.18",
    "message": "Hello from IDE"
}
{
    "id": 2,
    "ipAddress": "172.17.0.19",
    "message": "Hello from IDE"
}
{
    "id": 1,
    "ipAddress": "172.17.0.20",
    "message": "Hello from IDE"
}
----

### Configure `ipservice`

. Add Kubernetes Spring Cloud extension into pom file
+
Properties
+
[source,xml]
----
<spring-cloud.version>Brixton.SR7</spring-cloud.version>
<spring-cloud-kubernetes.version>0.1.6</spring-cloud-kubernetes.version>
----
+
Dependency management
+
[source,xml]
----
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-dependencies</artifactId>
    <version>${spring-cloud.version}</version>
    <type>pom</type>
    <scope>import</scope>
</dependency>
----
+
Dependencies:
+
[source,xml]
----
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-context</artifactId>
</dependency>
<dependency>
    <groupId>io.fabric8</groupId>
    <artifactId>spring-cloud-starter-kubernetes</artifactId>
    <version>${spring-cloud-kubernetes.version}</version>
</dependency>
----
+
. Create `ipserviceConfigMap.yml` with following content
+
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: ipservice
data:
  application.yaml: |-
    ipservice:
      message: hello, spring cloud kubernetes from Wroclaw!
----
+
. Import the file
+
----
oc create -f ipserviceConfigMap.yml
----
+
Test the changes
+
----
$ curl -s http://ipservice-default.192.168.99.100.xip.io/ip
{"id":5,"ipAddress":"172.17.0.19","message":"hello, spring cloud kubernetes from Wroclaw!"}
----
. Change the configuration using following command and test the changes again
+
----
$ oc edit configmap ipservice
----

### Create `ipclient` client application

. Create a client application similar to the previous
application, create the controlle
+
[source,java]
----
package com.capgemini.demos.k8s.ipclient;

....

@RestController
class IPAddressController {
    private int counter;

    private RestTemplate template = new RestTemplate();

    @RequestMapping(value = "/ip", method = RequestMethod.GET)
    public IPAddress ipaddress() throws Exception {
        RestTemplate template = new RestTemplate();
        return template.getForEntity("http://ipservice/ip", IPAddress.class).getBody();
    }
}
----
+
. Deploy the application using maven command
+
----
$ mvn clean install fabric8:build -Dfabric8.mode=openshift
$ mvn clean install fabric8:deploy
----
+
Check routes and test the service
+
----
$ oc get route
NAME             HOST/PORT                                      PATH      SERVICES         PORT       TERMINATION
ipclient         ipclient-default.192.168.99.100.xip.io                   ipclient         8080
ipservice        ipservice-default.192.168.99.100.xip.io                  ipservice        8080

$ for i in {1..10}; do curl -s http://ipclient-default.192.168.99.100.xip.io/ip |  python -m json.tool; done;
----
+
Scale out the `ipservice` and run the `ipclient` again.

### Add circuit breaker to `ipclient`

. Grant the view role to service accounts
+
----
$ oc policy add-role-to-user view system:serviceaccount:$(oc project -q):turbine
$ oc policy add-role-to-user view system:serviceaccount:$(oc project -q):name-client-service
----
+
. Deploy the Hystrix dashboard and the Turbine server
+
----
$ oc create -f hystrix/deploy.yml

$ oc get svc
NAME                      CLUSTER-IP       EXTERNAL-IP   PORT(S)                   AGE
hystrix-dashboard         172.30.160.199   <nodes>       80/TCP                    1m
ipclient                  172.30.82.220    <nodes>       80/TCP                    27m
ipservice                 172.30.12.104    <nodes>       80/TCP                    1h
turbine-server            172.30.167.183   <nodes>       80/TCP                    1m
----
+
. Add Hystrix support to the `ipclient`
+
Properties
+
[source,xml]
----
<spring-cloud.version>Brixton.SR7</spring-cloud.version>
<spring-cloud-kubernetes.version>0.1.6</spring-cloud-kubernetes.version>
----
+
Dependency management
+
[source,xml]
----
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-dependencies</artifactId>
    <version>${spring-cloud.version}</version>
    <type>pom</type>
    <scope>import</scope>
</dependency>
----
+
Dependency
+
[source,xml]
----
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-hystrix</artifactId>
</dependency>
----
+
. Implement the Hystrix command
+
[source,java]
----
@RequestMapping(value = "/ip", method = RequestMethod.GET)
@HystrixCommand(fallbackMethod = "localIP")
public IPAddress ipaddress() throws Exception {
....

public IPAddress localIP() throws UnknownHostException {
    return new IPAddress(++counter, InetAddress.getLocalHost().getHostAddress(),
            "This is a local response");
}
----
+
. Build and deploy the application
. Enable Hystrix for `ipclient` service, e.g.
+
----
$ oc edit svc ipclient

labels:
   expose: "true"
   hystrix.enabled: "true"
   ....
----
+
. Open the Hystric Dashboard. Obtain the url using
+
----
$ minishift service hystrix-dashboard --url
http://192.168.99.100:30050
----
+
Test the `ipclient`
+
----
$ for i in {1..1000}; do curl -s http://ipclient-default.192.168.99.100.xip.io/ip |  python -m json.tool; done;
----
+
. Scale out the `ipservice` to 0 replicas. Check the result. Scale in the service again.

### Cleanup the demo

----
$ oc delete all -l project=ipservice
$ oc delete all -l project=ipclient
----
